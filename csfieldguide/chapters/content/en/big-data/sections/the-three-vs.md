# Big Data and The Three V's

Being able to find patterns in huge amounts of data can be incredibly valuable for making decisions, setting prices, making recommendations, and detecting suspicious activities, which is why Big Data is a bit of a buzzword in the tech industry these days.
But how big does it have to be to be called "*Big Data*"? Big Data is a phrase used to mean an amount of data that is so large and incoming so quickly that it is difficult to store and analyse using traditional sequential programming and storage techniques.
Big Data has three main qualities: Volume, Velocity and Variety (often referred to as the "3Vs").

## Volume

Volume refers to the quantity of data.
Your phone might have about 64GB of storage space and it takes a long time for the typical smartphone user to run out of space.
A laptop might have 1TB of storage space, and some users will never get close to using all that space.
It wasn't long ago that running out of space was a common problem for users, but advances in engineering of transistor density have continued at a steady pace: doubling the capacity of a single computer's integrated circuit every two years ([Moore's Law](https://en.wikipedia.org/wiki/Moore%27s_law)), so if you're reading this several years after it was written 1TB might sound quite small!

So how big does data have to be to be considered big? Well, it usually starts in the terabytes, then petabytes, then exabytes, and so onâ€¦ Big Data is so big that simply storing it is an issue in itself; a single computer cannot store the amount of data on its own, and multiple computers must be used.

## Velocity

There are two ways to measure Velocity: the speed at which the data is being generated, and the speed at which it is being processed.
Have a look at this website showing what happens on the internet [every second](https://everysecond.io/the-internet) to get an idea of just how quickly data is produced online!
Big Data tends to be produced continually, and is available in real time.
For example, every time you make a purchase using your EFTPOS card, that transaction is recorded.
In New Zealand there are typically 50-60 EFTPOS transactions every single second, and this more than doubles in the Christmas period.

Every time you scroll through Facebook, that is generating data.
In September 2018, Facebook had an average of 1.49 billion active users each day.
Some of those users would have posted photos, liked posts, played games, sent messages, shared life events, etc.
All of this is generating data, which is recorded as it happens, and needs to be processed just as quickly as it is created in order for Facebook to see trends. Imagine all of a sudden there was no activity coming from Australasia.
That is likely to indicate an issue with their system in this part of the world, and Facebook needs to know about that immediately in order to diagnose and fix the problem.

## Variety

Variety refers to the many different types of data (plain text, images, videos, audio, and many more types) that are generated and stored.
Big Data almost always uses more than one data type, and this contributes to the complexity of it.
Different data types have different attributes and therefore the data doesn't simply fit into rows and columns of a spreadsheet or database (e.g. the dimensions of an image will not fit into the same field as the length of an audio clip).
